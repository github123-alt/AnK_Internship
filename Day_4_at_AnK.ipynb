{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiRdc2MyIbfs1Cp1mh1htI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/github123-alt/AnK_Internship/blob/main/Day_4_at_AnK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Qki373UHAjm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import backend as k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "nhPI7Gp3K0N4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "   inpx = (1, img_rows, img_cols)\n",
        "\n",
        "else:\n",
        "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "   inpx = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "GF8FTvPFY2D7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "rAjw-92NZSlN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inpx = Input(shape=inpx)\n",
        "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
        "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
        "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "layer4 = Dropout(0.5)(layer3)\n",
        "layer5 = Flatten()(layer4)\n",
        "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
        "layer7 = Dense(10, activation='softmax')(layer6)"
      ],
      "metadata": {
        "id": "B1aiWxEoZU5a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([inpx], layer7)\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=12, batch_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLSHyIVoZXFf",
        "outputId": "ea0d45ca-ff19-4a16-cd7b-d96b3f75bb8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.0972 - loss: 2.5308\n",
            "Epoch 2/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.0978 - loss: 2.5172\n",
            "Epoch 3/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.0970 - loss: 2.4947\n",
            "Epoch 4/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.0982 - loss: 2.4798\n",
            "Epoch 5/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.0975 - loss: 2.4663\n",
            "Epoch 6/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.0994 - loss: 2.4455\n",
            "Epoch 7/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.0967 - loss: 2.4347\n",
            "Epoch 8/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.0973 - loss: 2.4189\n",
            "Epoch 9/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.0963 - loss: 2.4060\n",
            "Epoch 10/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.0979 - loss: 2.3895\n",
            "Epoch 11/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.0983 - loss: 2.3742\n",
            "Epoch 12/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.0975 - loss: 2.3618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cb09655cad0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('loss=', score[0])\n",
        "print('accuracy=', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw8snwGZZZfF",
        "outputId": "ac0a2d9d-c5b2-4c56-ac6c-259526e02bae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss= 2.3509268760681152\n",
            "accuracy= 0.09839999675750732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explained:**"
      ],
      "metadata": {
        "id": "o4Y9Md4wxOep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "•\tEssential libraries for building and training neural networks were imported .\n",
        "\n",
        "•\tKeras is a high level API for building and training deep learning models.\n",
        "\n",
        "•\tMNIST database is imported from keras\n",
        "•\tModel is imported to configure, train and evaluate neural network\n",
        "\n",
        "•\tDense layer is fully connected layer where every neuron receives input from all neurons from previous layer\n",
        "\n",
        "•\tInput layer defines the shape of the data that the model is expected to receive.\n",
        "\n",
        "•\tConv2D performs 2D convolutions like image data processing\n",
        "\n",
        "•\tMaxpooling2D reduces the spatial dimensions of feature map\n",
        "\n",
        "•\tDropout prevents overfitting\n",
        "\n",
        "•\tFlatten to flatten the output of convolutional layers into 1D\n",
        "\n",
        "•\tBackend provides low level operations for working with tensors.\n",
        "\n",
        "•\tThen data is loaded from mnist. X_train contains array of images and y_train contains array of labels\n",
        "\n",
        "•\tDimension for images is set at 28x28\n",
        "\n",
        "•\tImage data format is checked and train/test were reshaped to include channel dimension\n",
        "\n",
        "•\tThe image data was converted from integers to floating values and pixel values were normalized by dividing with 255 to help neural network converge faster.\n",
        "\n",
        "•\tThen, integer labels of mnist dataset was converted to one hot encoded format. It is needed to train the model with categorical cross entropy loss function..\n",
        "\n",
        "•\tInpx defined the input layer of the model. The first convolutional layer was defined with 32 filters/kernels, 3x3 pixels and Rectified Linear Unit was used as activation function. Layer 3 is the max pooling layer which takes maximum value within each pool window of 3x3. Layer 4 applies dropout regularization with 50% of neurons is layer 3’s output set to zero. Layer 5 reshapes the previous layer to 1D vector. Layer 6 is the first fully connected layer which specifies 250 neurons\n",
        "\n",
        "•\tTraining progress for each epoch is outputted including loss and accuracy\n",
        "\n",
        "•\tThe trained model evaluated on the test dataset to access its performance on unseen data.\n"
      ],
      "metadata": {
        "id": "madvMABLxTqx"
      }
    }
  ]
}